metadata:
  deployedBy: null-value
  pipelineUrl: null-value

image:
  registry: docker.io
  repository: nginxinc/nginx-unprivileged
  tag: 1.23-alpine
  id: 1.23-alpine
  digest: ~
  pullPolicy: Always
  pullSecrets: []


updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    maxUnavailable: 20%
    maxSurge: 1

replicaCount: 1

externalUpstream:
  enabled: false
  serviceName: ~
  servicePort: 9000
  maxFails: 3
  failTimeout: 30

extraConfig:
  enabled: false
  content: |
    set_real_ip_from  127.0.0.0/24;
    set_real_ip_from  100.64.64.0/18;
    real_ip_header    X-Forwarded-For;
    real_ip_recursive on;
  

extraFilterIp:
  enabled: false
  defaultPermission: 'deny'
  forbiddenText: 'Not allowed'
  allow: []
  deny: []


containerPorts:
  http: 8080

extraVhostConfig:
  enabled: false
  content: ''

extraEnvVars: {}

extraEnvVarsSecrets: []

extraVolumeMounts: []

extraVolumes: []
## @param sidecars Add additional sidecar containers for the pod(s)
##
sidecars: []

resources:
  enabled: true
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # requests: {}
  # limits: {}
  requests:
    cpu: 25m
    memory: 128Mi
  limits:
    cpu: 100m
    memory: 128Mi



livenessProbe:
  enabled: true
  initialDelaySeconds: 5
  periodSeconds: 10
  timeoutSeconds: 1
  failureThreshold: 3
  successThreshold: 1

readinessProbe:
  enabled: true
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 1
  failureThreshold: 10
  successThreshold: 1

podSecurityContext:
  active: false  # set in yaml values
  enabled: false  # set in cli args
  fsGroup: 101
  runAsGroup: 101
  runAsUser: 101
  runAsNonRoot: true


containerSecurityContext:
  active: false  # set in yaml values
  enabled: false  # set in cli args
  allowPrivilegeEscalation: true
  capabilities:
    add:
#      - NET_BIND_SERVICE
#      - CHOWN
      - SETGID
      - SETUID
    drop:
      - ALL
  procMount: Default
  runAsUser: 101


## %%MAIN_CONTAINER_NAME%% service parameters
##
service:
  ## @param service.type %%MAIN_CONTAINER_NAME%% service type
  ##
  type: ClusterIP
  ## @param service.ports.http %%MAIN_CONTAINER_NAME%% service HTTP port
  ## @param service.ports.https %%MAIN_CONTAINER_NAME%% service HTTPS port
  ##
  ports:
    http: 80
    https: 443
  ## Node ports to expose
  ## @param service.nodePorts.http Node port for HTTP
  ## @param service.nodePorts.https Node port for HTTPS
  ## NOTE: choose port between <30000-32767>
  ##
  nodePorts:
    nginx: ""
  ## @param service.clusterIP %%MAIN_CONTAINER_NAME%% service Cluster IP
  ## e.g.:
  ## clusterIP: None
  ##
  clusterIP: ""
  ## @param service.loadBalancerIP %%MAIN_CONTAINER_NAME%% service Load Balancer IP
  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
  ##
  loadBalancerIP: ""
  ## @param service.loadBalancerSourceRanges %%MAIN_CONTAINER_NAME%% service Load Balancer sources
  ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
  ## e.g:
  ## loadBalancerSourceRanges:
  ##   - 10.10.10.0/24
  ##
  loadBalancerSourceRanges: []
  ## @param service.externalTrafficPolicy %%MAIN_CONTAINER_NAME%% service external traffic policy
  ## ref http://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
  ##
  externalTrafficPolicy: Cluster
  ## @param service.annotations Additional custom annotations for %%MAIN_CONTAINER_NAME%% service
  ##
  annotations: {}
  ## @param service.extraPorts Extra ports to expose in %%MAIN_CONTAINER_NAME%% service (normally used with the `sidecars` value)
  ##
  extraPorts: []
  ## @param service.sessionAffinity Control where client requests go, to the same pod or round-robin
  ## Values: ClientIP or None
  ## ref: https://kubernetes.io/docs/user-guide/services/
  ##
  sessionAffinity: None
  ## @param service.sessionAffinityConfig Additional settings for the sessionAffinity
  ## sessionAffinityConfig:
  ##   clientIP:
  ##     timeoutSeconds: 300
  ##
  sessionAffinityConfig: {}


## Configure the ingress resource that allows you to access the
## Nginx installation. Set up the URL
## ref: https://kubernetes.io/docs/user-guide/ingress/
##
ingress:
  ## @param ingress.enabled Set to true to enable ingress record generation
  ##
  enabled: false
  ## @param ingress.selfSigned Create a TLS secret for this ingress record using self-signed certificates generated by Helm
  ##
  selfSigned: false
  ## @param ingress.pathType Ingress path type
  ##
  pathType: ImplementationSpecific
  ## @param ingress.hostname Default host for the ingress resource
  ##
  hostname: nginx.local
  ## @param ingress.path The Path to Nginx. You may need to set this to '/*' in order to use this with ALB ingress controllers.
  ##
  path: /
  ## @param ingress.annotations Additional annotations for the Ingress resource. To enable certificate autogeneration, place here your cert-manager annotations.
  ## For a full list of possible ingress annotations, please see
  ## ref: https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md
  ## Use this parameter to set the required annotations for cert-manager, see
  ## ref: https://cert-manager.io/docs/usage/ingress/#supported-annotations
  ##
  ## e.g:
  ## annotations:
  ##   kubernetes.io/ingress.class: nginx
  ##   cert-manager.io/cluster-issuer: cluster-issuer-name
  ##
  annotations: {}
  ## @param ingress.ingressClassName Set the ingerssClassName on the ingress record for k8s 1.18+
  ## This is supported in Kubernetes 1.18+ and required if you have more than one IngressClass marked as the default for your cluster .
  ## ref: https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/
  ##
  ingressClassName: ""
  ## @param ingress.tls Create TLS Secret
  ## TLS certificates will be retrieved from a TLS secret with name: {{- printf "%s-tls" .Values.ingress.hostname }}
  ## You can use the ingress.secrets parameter to create this TLS secret or relay on cert-manager to create it
  ##
  tls: false
  ## @param ingress.extraHosts The list of additional hostnames to be covered with this ingress record.
  ## Most likely the hostname above will be enough, but in the event more hosts are needed, this is an array
  ## extraHosts:
  ## - name: nginx.local
  ##   path: /
  ##
  extraHosts: []
  ## @param ingress.extraPaths Any additional arbitrary paths that may need to be added to the ingress under the main host.
  ## For example: The ALB ingress controller requires a special rule for handling SSL redirection.
  ## extraPaths:
  ## - path: /*
  ##   backend:
  ##     serviceName: ssl-redirect
  ##     servicePort: use-annotation
  ##
  extraPaths: []
  ## @param ingress.extraTls The tls configuration for additional hostnames to be covered with this ingress record.
  ## see: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
  ## extraTls:
  ## - hosts:
  ##     - nginx.local
  ##   secretName: nginx.local-tls
  ##
  extraTls: []
  ## @param ingress.secrets If you're providing your own certificates, please use this to add the certificates as secrets
  ## key and certificate should start with -----BEGIN CERTIFICATE----- or
  ## -----BEGIN RSA PRIVATE KEY-----
  ##
  ## name should line up with a tlsSecret set further up
  ## If you're using cert-manager, this is unneeded, as it will create the secret for you if it is not set
  ##
  ## It is also possible to create and manage the certificates outside of this helm chart
  ## Please see README.md for more information
  ## e.g:
  ## - name: nginx.local-tls
  ##   key:
  ##   certificate:
  ##
  secrets: []
  ## @param ingress.extraRules The list of additional rules to be added to this ingress record. Evaluated as a template
  ## Useful when looking for additional customization, such as using different backend
  ##
  extraRules: []

# Mutually exclusive with autoscaling
autoscaling:
  active: false  # set in cli args
  enabled: false  # set in yaml values
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80
  behavior: {}
    # scaleDown:
    #   stabilizationWindowSeconds: 300
    #   policies:
    #   - type: Pods
    #     value: 1
    #     periodSeconds: 180
    # scaleUp:
    #   stabilizationWindowSeconds: 300
    #   policies:
    #   - type: Pods
    #     value: 2
    #     periodSeconds: 60

autoscalingTemplate: []
# Custom or additional autoscaling metrics
# ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-custom-metrics
# - type: Pods
#   pods:
#     metric:
#       name: app_process_requests_total
#     target:
#       type: AverageValue
#       averageValue: 10000m

## @param podLabels Extra labels for %%MAIN_CONTAINER_NAME%% pods
## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
##
podLabels: {}
## @param podAnnotations Annotations for %%MAIN_CONTAINER_NAME%% pods
## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
##
podAnnotations: {}

metrics:
  enabled: false
  image:
    registry: docker.io
    repository: nginx/nginx-prometheus-exporter
    tag: 0.9.0
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 15m
      memory: 20Mi

  serviceMonitor:
    enabled: true
    # serviceMonitor.labels -- labels to set on the vault serviceMonitor
    labels: {}
    # scrapeTimeout  -- scrapeTimeout of the serviceMonitor
    scrapeTimeout: 30s

    scrapeInterval: 30s

    # -- Specify the Kubernetes namespace where Prometheus expects to find
    # service monitors configured.
    # namespace: ""

commonAnnotations: []

commonLabels: []
